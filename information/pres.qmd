---
title: "Анализ Git репозиториев"
author: "ФИО <br>Москва 2025"
format:
  revealjs:
    theme: sky
    fontsize: 32px
---

## Цели

Проект может быть использован для следующих целей:

-   анализ благонадёжности пользователя как контрагента на основании его поведенческого профиля;
-   детектирование аномалий для предотвращения подмены кода в разрабатываемых проектах.

### Поведенческий профиль

Поведенческий профиль разработчика создаётся на основе его коммитов в репозитории своего профиля (по умолчанию - за год)

## Архитектура

Форма представления проекта: shiny-приложение

::: {style="text-align: center;"}
<br><img src="img/arck.png" width="80%"/>
:::

## Стек технологий

Будут использованы следующие технологии:

-   Backend: R
-   Frontend: Shiny
-   Data processing: dplyr, purrr, httr2, dummy
-   Визуализация: ggplot2, plotly, heatmaps
-   ML: PCA
-   Интеграции: GitHub API v3

# Фаза ETL данных

## Работа с репозиториями

::::: columns
::: {.column width="30%"}
### GitHub API

<img src="img/github-mark.png" width="80%"/>
:::

::: {.column width="70%"}
### Поэтапное формирование ETL

1.  Получение списка репозиториев разработчика;
2.  На основе полученной информации о репозиториях:
    1.  Формирование списка коммитов;
    2.  Формирование данных о forks и issues;
    3.  Формирование списка используемых ЯП;
    4.  Формирование тепловой карты по датам коммитов.
:::
:::::

## Программная реализация

::::: columns
::: {.column width="50%"}
### Используемые библиотеки:

-   httr2 - загрузка данных из API;
-   dplyr - очистка, преобразование и агрегирование данных, полученных из API;
-   purrr - преобразование данных и обработка ошибок.
:::

::: {.column width="50%"}

# Фаза аналитики & ML

## Обработка данных

::::: columns
::: {.column width="50%"}
Анализ характера вносимых изменений производится подсчётом количества добавленных, удалённых и изменённых строк.

Создание профиля разработчика происходит на основе данных о коммитах в его репозиториях. Подсчёт аномалий, на данный момент, высчитывается Методом главных компонент.
:::

::: {.column width="50%"}
### Нормализация данных, поэтапно:

1.  С помощью dummy, признаки разбиваются с категориальных на некатегориальные;
2.  Агрегация данных о коммитах;
3.  Нормализация методом MinMax;
4.  Определение главных компонентов;
5.  Определение аномалий по порогу выброса.
:::
:::::

## Программная реализация

::::: columns
::: {.column width="65%"}
### Используемые библиотеки:

:::

::: {.column width="35%"}

# Фаза визуализации

## Shiny

Визуализация простроена на Shiny.

::: {style="text-align: center;"}
<img src="img/Shiny_hex_logo.png" width="45%"/>
:::

## Автоотчёт

<img src="img/export.png" width="100%"/>

# Документация

## Документация в README

::: {style="text-align: center;"}
<img src="img/readme.png" width="80%"/>
:::

# Прототип

## Список репозиториев

<img src="img/strt.png" width="100%"/>

## Список коммитов

<img src="img/coms.png" width="100%"/>

## События

<img src="img/haps.png" width="100%"/>

## Распределение используемых языков

<img src="img/langs.png" width="100%"/>

## Тепловая карта активности

<img src="img/acts.png" width="100%"/>

## Подсчёт аномалий

<img src="img/pca.png" width="100%"/>
